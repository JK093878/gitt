import math
# from sched import scheduler
from sklearn.metrics import accuracy_score
from torch.optim.lr_scheduler import StepLR
# from torch.optim.lr_scheduler import OneCycleLR
from sched import scheduler as SchedScheduler
import seaborn as sns
import numpy as np
import pandas as pd
import psutil
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.impute import KNNImputer
from torch.utils.data import Dataset, DataLoader, Subset, dataset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt
import os
import logging
from sklearn.metrics import classification_report, confusion_matrix
# from models import WiFiLocalizationModel, DAE
from tqdm import tqdm

# è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡å¤æ€§
torch.manual_seed(42)
np.random.seed(42)

# è®¾å¤‡é…ç½®
# æ”¹ä¸ºå¼ºåˆ¶ä½¿ç”¨GPUï¼ˆå¦‚æœä¸å¯ç”¨åˆ™æŠ¥é”™ï¼‰
assert torch.cuda.is_available(), "CUDA is not available - GPU required!"
device = torch.device('cuda')
print(f"Using device: {device}")

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# è‡ªå®šä¹‰åˆå§‹åŒ–æ–¹æ³•
def my_init_sigmoid(shape):
    rnd = torch.rand(shape)
    fan_in = shape[0]
    fan_out = shape[1] if len(shape) > 1 else 1
    return 8. * (rnd - 0.5) * np.sqrt(6) / np.sqrt(fan_in + fan_out)


def my_init_others(shape):
    rnd = torch.rand(shape)
    fan_in = shape[0]
    return 2. * (rnd - 0.5) / np.sqrt(fan_in)


import torch.nn as nn
import torch.nn.functional as F


# ç®€å•ç”Ÿæˆå™¨
class RSSIGenerator(nn.Module):
    def __init__(self, noise_dim=100, output_dim=520):
        super(RSSIGenerator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(noise_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, output_dim),
            nn.Tanh()  # è¾“å‡ºèŒƒå›´çº¦æŸ
        )

    def forward(self, z):
        return self.model(z)


# åˆ¤åˆ«å™¨
class RSSIDiscriminator(nn.Module):
    def __init__(self, input_dim=520):
        super(RSSIDiscriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.LeakyReLU(0.2),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)


def train_gan_rssi(floor4_data, num_epochs=200, batch_size=64, noise_dim=100, device='cuda'):
    floor4_data = torch.tensor(floor4_data, dtype=torch.float32).to(device)
    dataset = torch.utils.data.TensorDataset(floor4_data)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    generator = RSSIGenerator(noise_dim=noise_dim, output_dim=floor4_data.shape[1]).to(device)
    discriminator = RSSIDiscriminator(input_dim=floor4_data.shape[1]).to(device)

    criterion = nn.BCELoss()
    optimizer_G = torch.optim.Adam(generator.parameters(), lr=1e-3)
    optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=1e-3)

    for epoch in range(num_epochs):
        for real_batch, in loader:
            batch_size = real_batch.size(0)
            real_labels = torch.ones(batch_size, 1).to(device)
            fake_labels = torch.zeros(batch_size, 1).to(device)

            # Train discriminator
            z = torch.randn(batch_size, noise_dim).to(device)
            fake_data = generator(z)
            d_loss = criterion(discriminator(real_batch), real_labels) + \
                     criterion(discriminator(fake_data.detach()), fake_labels)

            optimizer_D.zero_grad()
            d_loss.backward()
            optimizer_D.step()

            # Train generator
            z = torch.randn(batch_size, noise_dim).to(device)
            fake_data = generator(z)
            g_loss = criterion(discriminator(fake_data), real_labels)

            optimizer_G.zero_grad()
            g_loss.backward()
            optimizer_G.step()

    return generator


def extract_dae_features(dae, features, scaler):
    features = features.copy()
    features[features == 100] = -105
    features = scaler.transform(features)
    features_tensor = torch.FloatTensor(features).to(device)
    dae.eval()
    with torch.no_grad():
        encoded = dae.encoder(features_tensor)
    return encoded.cpu().numpy()


# æ•°æ®é¢„å¤„ç†ç±»
class WiFiDataset(Dataset):
    def __init__(self, data_path=None, features=None, labels=None,
                 coordinates=None, building_ids=None, seq_length=5,
                 imputer=None, scaler=None, columns_to_drop=None,  # æ–°å¢å‚æ•°
                 is_train=True):  # æ–°å¢è®­ç»ƒ/éªŒè¯æ ‡å¿—
        self.seq_length = seq_length
        self.is_train = is_train  # æ§åˆ¶æ˜¯å¦æ•°æ®å¢å¼º

        # æ•°æ®åŠ è½½ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        if data_path is not None:
            data = pd.read_csv(data_path)
            self.features = data.filter(regex='^WAP\d+').values
            self.labels = data['FLOOR'].values
            self.coordinates = data[['LONGITUDE', 'LATITUDE']].values
            self.building_ids = data['BUILDINGID'].values
        elif features is not None:
            self.features = features
            self.labels = labels
            self.coordinates = coordinates
            self.building_ids = building_ids if building_ids is not None else np.zeros(len(labels))
        else:
            raise ValueError("éœ€è¦æä¾› data_path æˆ– features/labels/coordinates ç­‰")

        # ç¡®ä¿floatç±»å‹
        self.features = self.features.astype(float)

        # === å…³é”®ä¿®æ”¹1ï¼šç¼ºå¤±å€¼å¤„ç† ===
        self.features[self.features == 100] = -105  # è®ºæ–‡æ¨èå€¼è€Œénp.nan

        # # ä»…è®­ç»ƒé›†è®¡ç®—éœ€è¦åˆ é™¤çš„åˆ—
        # if is_train and columns_to_drop is None:
        #     missing_values = pd.DataFrame(self.features).isna().mean() * 100
        #     threshold = 95
        #     self.columns_to_drop = missing_values[missing_values > threshold].index
        # else:
        #     self.columns_to_drop = columns_to_drop  # éªŒè¯é›†ä½¿ç”¨è®­ç»ƒé›†çš„columns_to_drop
        #
        # # åˆ é™¤é«˜ç¼ºå¤±ç‡åˆ—
        # if self.columns_to_drop is not None:
        #     self.features = np.delete(self.features, self.columns_to_drop, axis=1)

        # === å…³é”®ä¿®æ”¹2ï¼šKNNå¡«å…… ===
        self.imputer = None  # ä¸è¿›è¡Œå¡«å……
        # === å…³é”®ä¿®æ”¹3ï¼šæ ‡å‡†åŒ– ===
        if scaler is None:
            self.scaler = StandardScaler()
            self.features = self.scaler.fit_transform(self.features)  # è®­ç»ƒé›†è®¡ç®—mean/std
        else:
            self.scaler = scaler
            self.features = self.scaler.transform(self.features)  # éªŒè¯é›†ä½¿ç”¨è®­ç»ƒé›†çš„scaler

        # === å…³é”®ä¿®æ”¹4ï¼šæ•°æ®å¢å¼ºï¼ˆä»…è®­ç»ƒé›†ï¼‰===
        # if is_train:
        #     if self.labels[floor] in [0, 1, 2]:  # ä¸»ç±»
        #         self.features = self.add_noise(self.features, 0.2)
        #         self.features = channel_dropout(self.features, dropout_rate=0.1)
        #     else:  # å°‘æ•°ç±»ï¼Œä¸é®æŒ¡
        #         self.features = self.add_noise(self.features, 0.05)

        # 7. æ—¶åºå‚æ•°
        self.seq_length = seq_length

        # 8. æ•°æ®éªŒè¯
        assert len(self.features) == len(self.labels), "ç‰¹å¾ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…"
        assert len(self.features) == len(self.coordinates), "ç‰¹å¾ä¸åæ ‡æ•°é‡ä¸åŒ¹é…"
        if self.building_ids is not None:
            assert len(self.features) == len(self.building_ids), "ç‰¹å¾ä¸å»ºç­‘IDæ•°é‡ä¸åŒ¹é…"

        # è®¡ç®—num_classes
        self.num_buildings = len(np.unique(self.building_ids)) if self.building_ids is not None else 1
        self.num_floors = len(np.unique(self.labels))

        # æ¨¡å‹é…ç½®
        model_config = {
            'input_dim': 520,
            'spatial_feature_dim': 256,
            'temporal_hidden_dim': 128,
            'temporal_feature_dim': 256,
            'eca_channels': 512,
            'num_classes': None,
        }

        # å¦‚æœ building_ids ä¸º Noneï¼Œåˆ™è®¾ç½®ä¸ºå…¨é›¶æ•°ç»„
        if self.building_ids is None:
            self.building_ids = np.zeros_like(self.labels)

        print(f"ä¿®æ­£åæ ‡ç­¾èŒƒå›´: B={self.building_ids.min()}-{self.building_ids.max()}, "
              f"F={self.labels.min()}-{self.labels.max()}, ")

    def __len__(self):
        return len(self.features) - self.seq_length + 1

    def add_noise(self, data, noise_level=0.2):
        """æ·»åŠ é«˜æ–¯å™ªå£°è¿›è¡Œæ•°æ®å¢å¼º"""
        noise = np.random.normal(0, noise_level, data.shape)
        return data + noise

    def __getitem__(self, idx):

        # è·å–åºåˆ—ç‰¹å¾
        seq_features = self.features[idx:idx + self.seq_length]

        # è·å–åºåˆ—æ ‡ç­¾
        seq_labels = self.labels[idx:idx + self.seq_length]

        # è·å–åºåˆ—åæ ‡
        seq_coordinates = self.coordinates[idx:idx + self.seq_length]

        # è·å–åºåˆ—å»ºç­‘ID
        if self.building_ids is not None:
            seq_building_ids = self.building_ids[idx:idx + self.seq_length]
        else:
            seq_building_ids = np.zeros(self.seq_length)  # å¦‚æœæ²¡æœ‰å»ºç­‘IDï¼Œä½¿ç”¨0å¡«å……

        # åˆ›å»ºæ—¶é—´æˆ³
        timestamps = np.arange(self.seq_length)

        # è®¡ç®—ä½ç½®å˜åŒ–
        position_changes = np.sqrt(
            np.sum(np.diff(seq_coordinates, axis=0) ** 2, axis=1)
        )
        position_changes = np.pad(position_changes, (1, 0))  # åœ¨å¼€å§‹å¤„å¡«å……0

        # è½¬æ¢ä¸ºå¼ é‡
        features = torch.FloatTensor(seq_features)
        coordinates = torch.FloatTensor(seq_coordinates)
        hierarchical_labels = torch.LongTensor(np.column_stack((seq_building_ids, seq_labels)))
        # cluster_labels = torch.LongTensor(seq_space_ids)  # ä½¿ç”¨ç©ºé—´IDä½œä¸ºèšç±»æ ‡ç­¾
        timestamps = torch.FloatTensor(timestamps)
        position_changes = torch.FloatTensor(position_changes)

        return features, coordinates, hierarchical_labels, timestamps, position_changes


print("å¼€å§‹æ„å»ºæ•°æ®é›†...")

print("æ•°æ®é›†æ„å»ºå®Œæˆ")


class DAE(nn.Module):
    def __init__(self, input_dim, encoding_dim=128):
        super(DAE, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, encoding_dim),
            nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.Linear(encoding_dim, input_dim)
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded


# ä¿®æ”¹DAEå¤„ç†éƒ¨åˆ†ï¼Œä¿æŒä¸€è‡´çš„æ ‡å‡†åŒ–
# ä¿®æ”¹DAEå¤„ç†éƒ¨åˆ†ï¼Œä¿æŒä¸€è‡´çš„æ ‡å‡†åŒ–
def train_dae(features, encoding_dim=128, noise_std=0.02, epochs=30):
    features = features.copy()
    features[features == 100] = -105  # ä¿æŒä¸åç»­å¤„ç†ä¸€è‡´
    # ä½¿ç”¨StandardScalerè€Œä¸æ˜¯ç®€å•çš„çº¿æ€§å½’ä¸€åŒ–
    scaler = StandardScaler()
    features = scaler.fit_transform(features)
    # ...å…¶ä½™ä»£ç ä¸å˜...
    # æ„å»ºè¾“å…¥å¼ é‡
    features_tensor = torch.FloatTensor(features).to(device)

    input_dim = features.shape[1]
    dae = DAE(input_dim=input_dim, encoding_dim=encoding_dim).to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(dae.parameters(), lr=1e-3)

    # è®­ç»ƒ
    dae.train()
    for epoch in range(epochs):
        optimizer.zero_grad()
        noise = torch.randn_like(features_tensor) * noise_std
        noisy_input = torch.clamp(features_tensor + noise, 0, 1)
        outputs = dae(noisy_input)
        loss = criterion(outputs, features_tensor)
        loss.backward()
        optimizer.step()
    return dae


def apply_dae(dae, features):
    """ä½¿ç”¨è®­ç»ƒå¥½çš„DAEå»å™ª"""
    features = features.copy()
    features[features == 100] = -105
    features = (features + 105) / 105  # å½’ä¸€åŒ–åˆ°0~1

    features_tensor = torch.FloatTensor(features).to(device)

    dae.eval()
    with torch.no_grad():
        outputs = dae(features_tensor)

    # è¿˜åŸå›åŸå§‹RSSIèŒƒå›´
    denoised = outputs.cpu().numpy() * 105 - 105
    return denoised


# ECAæ¨¡å— (åŸºäºè®ºæ–‡ä¸­çš„å®ç°)
class ECAModule(nn.Module):
    def __init__(self, channels=128, gamma=2, b=1):
        super(ECAModule, self).__init__()
        self.channels = channels
        self.gamma = gamma
        self.b = b

        # è‡ªé€‚åº”ç¡®å®šå·ç§¯æ ¸å¤§å°
        t = int(abs((np.log2(self.channels) + self.b) / self.gamma))
        k = t if t % 2 else t + 1
        self.conv = nn.Conv1d(1, 1, kernel_size=k, padding=(k - 1) // 2, bias=False)

    def forward(self, x):
        # è¾“å…¥xçš„å½¢çŠ¶: (batch_size, seq_length, channels)
        batch_size, seq_length, channels = x.size()

        # é‡å¡‘ä¸º(batch_size * seq_length, channels)
        x_reshaped = x.reshape(-1, channels)

        # æ·»åŠ é€šé“ç»´åº¦ -> (batch_size * seq_length, 1, channels)
        x_channel = x_reshaped.unsqueeze(1)

        # é€šé“æ³¨æ„åŠ›
        y = self.conv(x_channel)  # shape: (batch_size * seq_length, 1, channels)
        y = torch.sigmoid(y).squeeze(1)  # shape: (batch_size * seq_length, channels)

        # åŠ æƒè¾“å…¥
        y = y.reshape(batch_size, seq_length, channels)

        # è¿”å›åŸå§‹è¾“å…¥ä¹˜ä»¥æ³¨æ„åŠ›æƒé‡
        return x * y


# 1D-CNNç½‘ç»œ (ç”¨äºç©ºé—´ç‰¹å¾æå–)
class SpatialFeatureExtractor(nn.Module):
    def __init__(self, input_dim=520, feature_dim=256):
        super(SpatialFeatureExtractor, self).__init__()
        self.conv1 = nn.Conv1d(1, 128, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm1d(128)
        self.conv2 = nn.Conv1d(128, 256, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm1d(256)
        self.conv3 = nn.Conv1d(256, feature_dim, kernel_size=3, padding=1)
        self.bn3 = nn.BatchNorm1d(feature_dim)
        self.pool = nn.AdaptiveAvgPool1d(1)
        self.relu = nn.ReLU()
        self._init_weights()  # æ·»åŠ è‡ªå®šä¹‰åˆå§‹åŒ–

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                shape = m.weight.shape
                m.weight.data = my_init_others(shape)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Linear):
                shape = m.weight.shape
                m.weight.data = my_init_sigmoid(shape)
                nn.init.zeros_(m.bias)

    def forward(self, x):
        # xå½¢çŠ¶: (batch_size, seq_len, input_dim)
        batch_size, seq_len, input_dim = x.size()

        # å¯¹æ¯ä¸ªæ—¶é—´æ­¥å•ç‹¬å¤„ç†
        spatial_features = []
        for t in range(seq_len):
            x_t = x[:, t, :].unsqueeze(1)  # (batch_size, 1, input_dim)

            # 1Då·ç§¯å¤„ç†
            out = self.relu(self.bn1(self.conv1(x_t)))
            out = self.relu(self.bn2(self.conv2(out)))
            out = self.relu(self.bn3(self.conv3(out)))

            # å…¨å±€å¹³å‡æ± åŒ–
            out = self.pool(out).squeeze(-1)  # (batch_size, feature_dim)
            spatial_features.append(out.unsqueeze(1))

        # åˆå¹¶æ‰€æœ‰æ—¶é—´æ­¥
        spatial_features = torch.cat(spatial_features, dim=1)  # (batch_size, seq_len, feature_dim)
        return spatial_features


# GRUç½‘ç»œ (ç”¨äºæ—¶é—´ç‰¹å¾æå–)
class TemporalFeatureExtractor(nn.Module):
    def __init__(self, input_dim, hidden_dim, feature_dim):
        super(TemporalFeatureExtractor, self).__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(2 * hidden_dim, feature_dim)
        self.relu = nn.ReLU()
        self._init_weights()

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                shape = m.weight.shape
                m.weight.data = my_init_sigmoid(shape)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)

    def forward(self, x):
        # xå½¢çŠ¶: (batch_size, seq_len, input_dim)
        gru_out, _ = self.gru(x)  # (batch_size, seq_len, 2*hidden_dim)

        # å¯¹æ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾è¿›è¡Œå˜æ¢
        temporal_features = self.relu(self.fc(gru_out))  # (batch_size, seq_len, feature_dim)
        return temporal_features


class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2):
        super(FocalLoss, self).__init__()
        self.alpha = alpha  # æƒé‡ï¼Œå¯ä»¥ä¼ å…¥ floor_weights
        self.gamma = gamma

    def forward(self, inputs, targets):
        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)
        pt = torch.exp(-ce_loss)
        loss = ((1 - pt) ** self.gamma) * ce_loss
        return loss.mean()


# ä¸»æ¨¡å‹
class WiFiLocalizationModel(nn.Module):
    def __init__(self, config):
        super().__init__()

        # å¢åŠ ä¸“é—¨çš„æ¥¼å±‚ç‰¹å¾æå–å±‚
        self.floor_specific_extractor = nn.Sequential(
            nn.Linear(config['temporal_feature_dim'], 128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.3)
        )

        # ä¿®æ”¹åˆ†ç±»å¤´
        self.floor_classifier = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, config['num_floors'])
        )

        self.attn_weights = nn.Sequential(
            nn.Linear(512, 128),
            nn.Tanh(),
            nn.Linear(128, 1)
        )

        self.config = config
        self.building_classifier = nn.Linear(512, config['num_buildings'])
        self.floor_classifier = nn.Linear(512, config['num_floors'])
        # self.coord_regressor = nn.Linear(512, 2)  # å›å½’ç»çº¬åº¦ï¼ˆLONGITUDE, LATITUDEï¼‰
        # å¢åŠ æ›´æ·±çš„åæ ‡å›å½’å™¨
        # æ›´å¼ºå¤§çš„åæ ‡å›å½’å™¨
        # åŠ å¼ºåæ ‡å›å½’å™¨ï¼ˆåœ¨WiFiLocalizationModelä¸­ï¼‰
        self.coord_regressor = nn.Sequential(
            nn.Linear(512, 512),
            nn.SiLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.SiLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.SiLU(),
            nn.Linear(128, 2)
        )

        # æ·»åŠ å¤šå°ºåº¦æ—¶ç©ºç‰¹å¾èåˆ
        self.spatial_attention = nn.Sequential(
            nn.Conv1d(256, 1, kernel_size=1),
            nn.Sigmoid()
        )

        # å¢åŠ æ›´å¼ºå¤§çš„ç‰¹å¾æå–å±‚
        self.spatial_extractor = nn.Sequential(
            SpatialFeatureExtractor(input_dim=config['input_dim'], feature_dim=config['spatial_feature_dim']),
            nn.LayerNorm(config['spatial_feature_dim']),
            nn.Dropout(0.5)
        )

        # å¢å¼ºæ—¶é—´ç‰¹å¾æå–
        self.temporal_extractor = nn.Sequential(
            TemporalFeatureExtractor(
                input_dim=config['input_dim'],
                hidden_dim=config['temporal_hidden_dim'],
                feature_dim=config['temporal_feature_dim']
            ),
            nn.LayerNorm(config['temporal_feature_dim']),
            nn.Dropout(0.5)
        )
        # ECAæ¨¡å—
        self.eca = nn.Sequential(
            ECAModule(channels=config['eca_channels']),
            nn.Dropout(0.3)
        )

        # å…¨è¿æ¥å±‚åŠå½’ä¸€åŒ–
        self.fc1 = nn.Linear(config['eca_channels'], 512)
        self.layer_norm = nn.LayerNorm(512)  # ğŸ” æ›¿ä»£ BatchNorm1d
        self.fc2 = nn.Linear(512, config['num_classes'])

        self.relu = nn.ReLU()
        self.dropout1 = nn.Dropout(0.5)
        self.dropout2 = nn.Dropout(0.7)

        # GMMå‚æ•°
        self.num_classes = config['num_classes']
        self.gmm = None

    # æ›¿æ¢åŸæ¥çš„ forward
    def forward(self, x, return_features=False):
        spatial_features = self.spatial_extractor(x)
        temporal_features = self.temporal_extractor(x)
        shared_features = torch.cat([spatial_features, temporal_features], dim=2)
        shared_features = self.eca(shared_features)

        # ä¸‹æ¸¸åˆ†æ”¯
        fc_out = self.relu(self.layer_norm(self.fc1(shared_features)))
        fc_out = self.dropout1(fc_out)
        fc_out = self.dropout2(fc_out)  # âœ… æ·»åŠ è¿™ä¸€è¡Œ

        # åˆ†ç±»ï¼šé€æ—¶é—´æ­¥
        building_logits = self.building_classifier(fc_out)
        floor_logits = self.floor_classifier(fc_out)

        # å›å½’ï¼šå¹³å‡æ± åŒ–åè¾“å‡ºåæ ‡
        # è®¡ç®— attention æƒé‡
        attn_scores = self.attn_weights(fc_out).squeeze(-1)  # (B, T)
        attn_weights = torch.softmax(attn_scores, dim=1).unsqueeze(-1)  # (B, T, 1)

        # åŠ æƒæ±‚å’Œæ›¿ä»£ mean pooling
        attn_pooled = torch.sum(fc_out * attn_weights, dim=1)  # (B, 512)
        coord_pred = self.coord_regressor(attn_pooled)

        if return_features:
            return (building_logits, floor_logits, coord_pred), shared_features
        return building_logits, floor_logits, coord_pred


def train_epoch(model, train_loader, criterion, floor_loss_fn, optimizer, device, coord_mean, coord_std,
                flood_level=0.3):
    model.train()
    total_loss = 0
    coord_mae = 0

    if not isinstance(coord_mean, torch.Tensor):
        coord_mean = torch.tensor(coord_mean, dtype=torch.float32, device=device)
    if not isinstance(coord_std, torch.Tensor):
        coord_std = torch.tensor(coord_std, dtype=torch.float32, device=device)

    all_true_building, all_pred_building = [], []
    all_true_floor, all_pred_floor = [], []

    for features, coordinates, hierarchical_labels, _, _ in train_loader:
        features = features.to(device)
        coordinates = coordinates.to(device)
        hierarchical_labels = hierarchical_labels.to(device)

        building_outputs, floor_outputs, coord_outputs = model(features)

        # === åˆ†ç±»æŸå¤±ï¼ˆå»ºç­‘ & æ¥¼å±‚ï¼‰===
        building_loss = criterion(
            building_outputs.reshape(-1, model.config['num_buildings']),
            hierarchical_labels[:, :, 0].reshape(-1)
        )
        floor_loss = floor_loss_fn(
            floor_outputs.reshape(-1, model.config['num_floors']),
            hierarchical_labels[:, :, 1].reshape(-1)
        )

        # === åæ ‡å›å½’æŸå¤±ï¼ˆåœ¨æ ‡å‡†åŒ–ç©ºé—´ä¸­è®¡ç®—ï¼‰===
        coord_target = coordinates.mean(dim=1)
        mae_loss = nn.L1Loss()(coord_outputs, coord_target)
        mse_loss = nn.MSELoss()(coord_outputs, coord_target)
        coord_loss = 0.7 * mae_loss + 0.3 * torch.sqrt(mse_loss + 1e-6)

        # === åæ ‡è¯¯å·®ç›‘æ§ï¼ˆåœ¨çœŸå®åæ ‡ç©ºé—´ä¸­ï¼Œå•ä½ï¼šç±³ï¼‰===
        coord_outputs_real = coord_outputs * coord_std + coord_mean
        coord_target_real = coord_target * coord_std + coord_mean
        errors = torch.norm(coord_outputs_real - coord_target_real, dim=1)
        coord_mae += torch.mean(errors).item()

        # === æ€»æŸå¤± ===
        loss = 0.3 * building_loss + 1.0 * floor_loss + 0.7 * coord_loss  # æƒé‡å¯è°ƒ
        # ====== æ–°å¢ï¼šFlooding æŠ€æœ¯ ======
        if flood_level > 0:
            loss = (loss - flood_level).abs() + flood_level  # Flooding å…¬å¼
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

        # === è®°å½•é¢„æµ‹ ===
        _, building_pred = torch.max(building_outputs[:, -1, :], dim=1)
        _, floor_pred = torch.max(floor_outputs[:, -1, :], dim=1)
        all_true_building.extend(hierarchical_labels[:, -1, 0].cpu().numpy())
        all_pred_building.extend(building_pred.cpu().numpy())
        all_true_floor.extend(hierarchical_labels[:, -1, 1].cpu().numpy())
        all_pred_floor.extend(floor_pred.cpu().numpy())

    # === ç²¾åº¦ç»Ÿè®¡ ===
    building_acc = accuracy_score(all_true_building, all_pred_building)
    floor_acc = accuracy_score(all_true_floor, all_pred_floor)

    return {
        'loss': total_loss / len(train_loader),
        'building_acc': building_acc,
        'floor_acc': floor_acc,
        'coord_mae': coord_mae / len(train_loader)
    }


def validate_epoch(model, val_loader, criterion, floor_loss_fn, device, coord_mean, coord_std):
    model.eval()
    total_loss = 0
    coord_mae = 0
    all_errors = []

    coord_mean = torch.tensor(coord_mean, dtype=torch.float32, device=device)
    coord_std = torch.tensor(coord_std, dtype=torch.float32, device=device)

    all_true_building, all_pred_building = [], []
    all_true_floor, all_pred_floor = [], []

    with torch.no_grad():
        for batch_idx, (features, coordinates, hierarchical_labels, _, _) in enumerate(val_loader):
            features = features.to(device)
            coordinates = coordinates.to(device)
            hierarchical_labels = hierarchical_labels.to(device)

            # å‰å‘ä¼ æ’­
            building_outputs, floor_outputs, coord_outputs = model(features)

            # --- åˆ†ç±»é¢„æµ‹ ---
            _, building_pred = torch.max(building_outputs[:, -1, :], dim=1)
            _, floor_pred = torch.max(floor_outputs[:, -1, :], dim=1)

            # === æ ¸å¿ƒä¿®æ”¹ï¼šå¯¹Floor 4çš„é¢„æµ‹è¿›è¡Œå»ºç­‘çº¦æŸä¿®æ­£ ===
            floor4_mask = (floor_pred == 4)  # æ‰¾åˆ°æ‰€æœ‰é¢„æµ‹ä¸ºFloor 4çš„æ ·æœ¬
            if torch.any(floor4_mask):
                # å‡è®¾å»ºç­‘2æ‰æœ‰Floor 4ï¼ˆæ ¹æ®æ•°æ®é›†å®é™…æƒ…å†µè°ƒæ•´ï¼‰
                invalid_building = (building_pred[floor4_mask] != 2)
                # å°†"å»ºç­‘ä¸æ˜¯2ä½†é¢„æµ‹ä¸ºFloor 4"çš„æ ·æœ¬ä¿®æ­£ä¸ºå»ºç­‘çš„æœ€é«˜æ¥¼å±‚
                floor_pred[floor4_mask] = torch.where(
                    invalid_building,
                    3,  # ä¿®æ­£ä¸ºæ¥¼å±‚3ï¼ˆå‡è®¾å»ºç­‘0/1çš„æœ€é«˜æ¥¼å±‚æ˜¯3ï¼‰
                    floor_pred[floor4_mask]  # å¦åˆ™ä¿æŒåŸé¢„æµ‹
                )

            all_true_building.extend(hierarchical_labels[:, -1, 0].cpu().numpy())
            all_pred_building.extend(building_pred.cpu().numpy())
            all_true_floor.extend(hierarchical_labels[:, -1, 1].cpu().numpy())
            all_pred_floor.extend(floor_pred.cpu().numpy())

            # --- åæ ‡è¯¯å·®è®¡ç®— ---
            # æ›¿æ¢ä¸ºï¼ˆåºåˆ—æœ«å°¾ä½ç½®ï¼‰ï¼š
            coord_target = coordinates.mean(dim=1)  # ä¸è®­ç»ƒä¸€è‡´
            coord_outputs_real = coord_outputs * coord_std + coord_mean
            coord_target_real = coord_target * coord_std + coord_mean
            errors = torch.norm(coord_outputs_real - coord_target_real, dim=1)
            coord_mae += torch.mean(errors).item()
            all_errors.extend(errors.cpu().numpy())  # âœ… æ–°å¢

            # æŸå¤±è®¡ç®—ï¼ˆä»…ç”¨äºç›‘æ§ï¼‰
            building_loss = criterion(
                building_outputs.reshape(-1, model.config['num_buildings']),
                hierarchical_labels[:, :, 0].reshape(-1)
            )
            floor_loss = nn.CrossEntropyLoss()(
                floor_outputs.reshape(-1, model.config['num_floors']),
                hierarchical_labels[:, :, 1].reshape(-1)
            )
            coord_loss = nn.MSELoss()(coord_outputs, coord_target)
            total_loss += (0.3 * building_loss + 1.0 * floor_loss + 0.7 * coord_loss).item()

    # åˆ†ç±»æŠ¥å‘Š
    print("\nğŸ“Š åˆ†ç±»æŠ¥å‘Šï¼š")
    print(classification_report(all_true_floor, all_pred_floor,
                                target_names=["Floor 0", "Floor 1", "Floor 2", "Floor 3", "Floor 4"]))

    return {
        'loss': total_loss / len(val_loader),
        'building_acc': accuracy_score(all_true_building, all_pred_building),
        'floor_acc': accuracy_score(all_true_floor, all_pred_floor),
        'coord_mae': coord_mae / len(val_loader),  # çœŸå®MAEï¼ˆç±³ï¼‰
        'errors': all_errors  # âœ… æ–°å¢
    }


def train_model(model, train_loader, val_loader, criterion, optimizer,
                floor_loss_fn, coord_mean, coord_std, scheduler,
                num_epochs, patience, device, flood_level=0.3):
    model = model.to(device)
    train_losses = []
    val_losses = []
    best_val_loss = float('inf')
    patience_counter = 0

    # æ·»åŠ è®°å½•å®¹å™¨
    history = {
        'train_building': [],
        'val_building': [],
        'train_floor': [],
        'val_floor': []
    }

    # âœ… åˆå§‹åŒ– EMA å‚æ•°å­—å…¸
    ema_decay = 0.999
    shadow_params = {name: param.data.clone() for name, param in model.named_parameters()}

    for epoch in tqdm(range(num_epochs), desc="Training Progress"):
        # è®­ç»ƒä¸€ä¸ªepoch
        train_metrics = train_epoch(model, train_loader, criterion, floor_loss_fn,
                                    optimizer, device, coord_mean, coord_std, flood_level=flood_level)
        train_losses.append(train_metrics['loss'])

        # éªŒè¯
        val_metrics = validate_epoch(model, val_loader, criterion, floor_loss_fn,
                                     device, coord_mean, coord_std)
        val_losses.append(val_metrics['loss'])
        scheduler.step()
        # è®°å½•æŒ‡æ ‡ï¼ˆæ”¾åœ¨æ‰“å°æŒ‡æ ‡ä¹‹åï¼‰
        history['train_building'].append(train_metrics['building_acc'])
        history['val_building'].append(val_metrics['building_acc'])
        history['train_floor'].append(train_metrics['floor_acc'])
        history['val_floor'].append(val_metrics['floor_acc'])

        # æ›´æ–°EMAå‚æ•°
        for name, param in model.named_parameters():
            if name in shadow_params:
                shadow_params[name].mul_(ema_decay).add_(param.data, alpha=1 - ema_decay)

        # è°ƒæ•´å­¦ä¹ ç‡
        # scheduler.step(val_metrics['loss'])

        # âœ… æ‰“å°å½“å‰å­¦ä¹ ç‡
        current_lr = optimizer.param_groups[0]['lr']
        print(f"å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}")

        # æ‰“å°æŒ‡æ ‡
        print(f'Epoch {epoch + 1}/{num_epochs}:')
        print(f'Train Loss: {train_metrics["loss"]:.4f}')
        print(f'Val Loss: {val_metrics["loss"]:.4f}')
        # åœ¨train_modelå‡½æ•°ä¸­ä¿®æ”¹æ‰“å°éƒ¨åˆ†
        print(f'Building Acc: {train_metrics["building_acc"]:.4f}/{val_metrics["building_acc"]:.4f}')
        print(f'Floor Acc: {train_metrics["floor_acc"]:.4f}/{val_metrics["floor_acc"]:.4f}')
        # print(f'Coord RMSE: {train_metrics["coord_rmse"]:.2f}/{val_metrics["coord_rmse"]:.2f}')
        # print(f'Coord MSE: {train_metrics["coord_mse"]:.2f}/{val_metrics["coord_mse"]:.2f}')
        print(f'Coord MAE (Mean Positioning Error): {train_metrics["coord_mae"]:.2f}/{val_metrics["coord_mae"]:.2f}')

        # âœ… æ·»åŠ å†…å­˜ç›‘æ§
        mem = psutil.virtual_memory()
        print(f"Memory usage: {mem.percent}%")

        # === æ—©åœæ£€æŸ¥ + ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆåŸºäºEMAï¼‰===
        if val_metrics['loss'] < best_val_loss:
            best_val_loss = val_metrics['loss']
            patience_counter = 0

            # ä¿å­˜å½“å‰æ­£å¸¸å‚æ•°æ¨¡å‹ä½œä¸ºå¤‡ä»½
            torch.save(model.state_dict(), 'best_model_normal.pth')

            # å°† shadow EMA å‚æ•°èµ‹å€¼ç»™æ¨¡å‹å†ä¿å­˜
            backup = {name: param.data.clone() for name, param in model.named_parameters()}
            for name, param in model.named_parameters():
                if name in shadow_params:
                    param.data.copy_(shadow_params[name])
            torch.save(model.state_dict(), 'best_model.pth')
            print("âœ… EMAå¹³æ»‘å‚æ•°å·²ä¿å­˜ä¸º best_model.pth")

            # æ¢å¤åŸå‚æ•°ï¼Œç»§ç»­è®­ç»ƒ
            for name, param in model.named_parameters():
                if name in backup:
                    param.data.copy_(backup[name])
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f'Early stopping triggered after {epoch + 1} epochs')
                break

    # æŸå¤±æ›²çº¿ç»˜å›¾
    plt.figure(figsize=(10, 4))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training vs Validation Loss')
    plt.legend()
    plt.grid()
    plt.savefig('loss_curve.png')
    print("âœ… æŸå¤±æ›²çº¿å·²ä¿å­˜åˆ° loss_curve.png")

    # è®­ç»ƒç»“æŸåç»˜åˆ¶ç²¾åº¦æ›²çº¿ï¼ˆæ”¾åœ¨returnä¹‹å‰ï¼‰
    plt.figure(figsize=(10, 4))

    # å»ºç­‘åˆ†ç±»ç²¾åº¦æ›²çº¿
    plt.subplot(1, 2, 1)
    plt.plot(history['train_building'], 'b-', label='Train')
    plt.plot(history['val_building'], 'r--', label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Building Accuracy')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)

    # æ¥¼å±‚åˆ†ç±»ç²¾åº¦æ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(history['train_floor'], 'b-', label='Train')
    plt.plot(history['val_floor'], 'r--', label='Validation')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Floor Accuracy')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)

    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("âœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜ä¸º training_curves.png")

    # âœ… æ–°å¢ç»˜åˆ¶ CDF å›¾
    val_errors = val_metrics.get('errors', None)
    if val_errors is not None:
        errors_np = np.sort(np.array(val_errors))
        cdf = np.arange(len(errors_np)) / len(errors_np)

        plt.figure(figsize=(8, 6))
        plt.plot(errors_np, cdf, label='CDF of Localization Error')
        plt.xlabel('Localization Error (meters)')
        plt.ylabel('Cumulative Probability')
        plt.title('CDF of Validation Localization Error')
        plt.grid(True)
        plt.legend()
        plt.tight_layout()
        plt.savefig('val_error_cdf.png')
        print("âœ… éªŒè¯é›†å®šä½è¯¯å·®CDFå›¾å·²ä¿å­˜ä¸º val_error_cdf.png")

    return train_losses, val_losses


#
# # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
def augment_rssi_with_noise(df, noise_std=2.0):
    wap_columns = df.filter(regex='^WAP').columns
    df_aug = df.copy()
    noise = np.random.normal(0, noise_std, size=df_aug[wap_columns].shape)
    df_aug[wap_columns] = df_aug[wap_columns] + noise
    df_aug[wap_columns] = df_aug[wap_columns].clip(-105, 0)
    return df_aug


def load_and_preprocess_data(train_data_path='/kaggle/input/UjiIndoorLoc/TrainingData.csv',
                             val_data_path='/kaggle/input/UjiIndoorLoc/ValidationData.csv',
                             seq_length=5, train_subset_ratio=1.0):
    # è·¯å¾„æ£€æŸ¥
    if not os.path.exists(train_data_path):
        raise FileNotFoundError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{train_data_path}")
    if not os.path.exists(val_data_path):
        raise FileNotFoundError(f"éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{val_data_path}")

    # åŠ è½½æ•°æ®
    train_data = pd.read_csv(train_data_path)
    val_data = pd.read_csv(val_data_path)

    from sklearn.cluster import KMeans

    print("ğŸ” å¼€å§‹å¢å¼º Floor 4 æ ·æœ¬")

    floor4_data = train_data[train_data['FLOOR'] == 4].copy()
    floor4_rssi = floor4_data.filter(regex='^WAP').values

    floor4_rssi[floor4_rssi == 100] = -105
    floor4_rssi = (floor4_rssi + 105) / 105 * 2 - 1  # [-1, 1]

    # âœ… è®­ç»ƒ GAN
    rssi_gan = train_gan_rssi(floor4_rssi, num_epochs=100)

    # âœ… å‡†å¤‡å¢å¼ºæ ·æœ¬æ€»æ•°
    num_to_generate = 2000
    z = torch.randn(num_to_generate, 100).to(device)
    synthetic_rssi = rssi_gan(z).detach().cpu().numpy()
    synthetic_rssi = (synthetic_rssi + 1) / 2 * 105 - 105
    synthetic_rssi = np.clip(synthetic_rssi, -105, 0)

    synthetic_df = pd.DataFrame(synthetic_rssi, columns=train_data.filter(regex='^WAP').columns)
    synthetic_df['FLOOR'] = 4
    synthetic_df['BUILDINGID'] = 2  # âœ… ä½ æ•°æ®ä¸­ Floor 4 æ‰€å± Building ID

    # âœ… åˆ©ç”¨ KMeans å¯¹ Floor 4 çš„åŸå§‹æ ·æœ¬ä½ç½®è¿›è¡Œç©ºé—´åˆ’åˆ†
    num_clusters = 4
    kmeans = KMeans(n_clusters=4, n_init=10, random_state=42)

    coords = floor4_data[['LONGITUDE', 'LATITUDE']].values
    cluster_labels = kmeans.fit_predict(coords)

    # å°†æ¯ä¸ª cluster çš„ç»çº¬åº¦é‡‡æ ·èµ‹å€¼ç»™ synthetic_df å­é›†
    samples_per_cluster = num_to_generate // num_clusters
    synthetic_parts = []

    for i in range(num_clusters):
        cluster_mask = cluster_labels == i
        cluster_coords = coords[cluster_mask]
        if len(cluster_coords) < 2:
            continue

        lon_mean, lon_std = cluster_coords[:, 0].mean(), cluster_coords[:, 0].std()
        lat_mean, lat_std = cluster_coords[:, 1].mean(), cluster_coords[:, 1].std()

        synth_part = synthetic_df.iloc[i * samples_per_cluster:(i + 1) * samples_per_cluster].copy()
        synth_part['LONGITUDE'] = np.random.normal(lon_mean, lon_std, size=len(synth_part))
        synth_part['LATITUDE'] = np.random.normal(lat_mean, lat_std, size=len(synth_part))

        synthetic_parts.append(synth_part)

    # æ‹¼æ¥æ‰€æœ‰èšç±»æ ·æœ¬
    synthetic_df_final = pd.concat(synthetic_parts, ignore_index=True)

    # åˆå¹¶åˆ°è®­ç»ƒé›†
    train_data = pd.concat([train_data, synthetic_df_final], ignore_index=True)

    print(f"âœ… Floor 4 æ ·æœ¬å¢å¼ºåæ•°é‡: {len(train_data[train_data['FLOOR'] == 4])}")

    # æ ‡ç­¾ä¿®æ­£ï¼ˆBUILDINGID/FLOOR ä» 0 å¼€å§‹ï¼‰
    for col in ['BUILDINGID', 'FLOOR']:
        # è®¡ç®—è®­ç»ƒé›†çš„æœ€å°å€¼
        train_min = train_data[col].min()
        # è°ƒæ•´è®­ç»ƒé›†æ ‡ç­¾
        train_data[col] -= train_min
        # éªŒè¯é›†ä½¿ç”¨ç›¸åŒçš„è°ƒæ•´å€¼
        val_data[col] -= train_min

    # éªŒè¯æ ‡ç­¾æ˜¯å¦ä»0å¼€å§‹
    assert train_data['BUILDINGID'].min() == 0
    assert train_data['FLOOR'].min() == 0
    assert val_data['BUILDINGID'].min() == 0
    assert val_data['FLOOR'].min() == 0

    print("è®­ç»ƒé›†æ ‡ç­¾èŒƒå›´:")
    print(f"Building IDèŒƒå›´: {train_data['BUILDINGID'].min()} - {train_data['BUILDINGID'].max()}")
    print(f"Floor IDèŒƒå›´: {train_data['FLOOR'].min()} - {train_data['FLOOR'].max()}")

    print("\néªŒè¯é›†æ ‡ç­¾èŒƒå›´:")
    print(f"Building IDèŒƒå›´: {val_data['BUILDINGID'].min()} - {val_data['BUILDINGID'].max()}")
    print(f"Floor IDèŒƒå›´: {val_data['FLOOR'].min()} - {val_data['FLOOR'].max()}")

    num_buildings = int(train_data['BUILDINGID'].max()) + 1
    num_floors = int(train_data['FLOOR'].max()) + 1

    print(f"æ¨¡å‹é…ç½®:")
    print(f"å»ºç­‘ç‰©æ•°é‡: {num_buildings}")
    print(f"æ¥¼å±‚æ•°é‡: {num_floors}")

    # è®¡ç®—è®­ç»ƒé›†å’ŒéªŒè¯é›†æ¯æ ‹æ¯å±‚çš„æ ·æœ¬æ•°
    train_building_floor_counts = train_data.groupby(['BUILDINGID', 'FLOOR']).size()
    val_building_floor_counts = val_data.groupby(['BUILDINGID', 'FLOOR']).size()

    # åŸå§‹åæ ‡
    coord_train = train_data[['LONGITUDE', 'LATITUDE']].values
    coord_val = val_data[['LONGITUDE', 'LATITUDE']].values

    # è®¡ç®—å‡å€¼æ–¹å·®
    coord_mean = coord_train.mean(axis=0)
    coord_std = coord_train.std(axis=0)

    # æ ‡å‡†åŒ–ï¼ˆæ¨èï¼‰
    coord_train = (coord_train - coord_mean) / coord_std
    coord_val = (coord_val - coord_mean) / coord_std

    building_ids_train = train_data['BUILDINGID'].values
    floor_ids_train = train_data['FLOOR'].values
    building_ids_val = val_data['BUILDINGID'].values
    floor_ids_val = val_data['FLOOR'].values

    # åŸCDAEä»£ç æ›¿æ¢ä¸º:
    print("Training DAE model...")
    dae = train_dae(
        features=train_data.filter(regex='^WAP').values,
        encoding_dim=128
    )

    print("Applying DAE to train/val data...")
    denoised_train_features = apply_dae(
        dae,
        features=train_data.filter(regex='^WAP').values
    )

    denoised_val_features = apply_dae(
        dae,
        features=val_data.filter(regex='^WAP').values
    )

    # 5. åˆ›å»ºæ•°æ®é›†ï¼ˆä¼ å…¥å»å™ªåçš„ç‰¹å¾ï¼‰
    train_dataset = WiFiDataset(
        features=denoised_train_features,
        labels=train_data['FLOOR'].values,
        building_ids=train_data['BUILDINGID'].values,
        coordinates=coord_train,
        seq_length=seq_length,
        is_train=True  # æ ‡è®°è®­ç»ƒé›†
    )

    val_dataset = WiFiDataset(
        features=denoised_val_features,
        labels=val_data['FLOOR'].values,
        building_ids=val_data['BUILDINGID'].values,
        coordinates=coord_val,
        seq_length=seq_length,
        imputer=train_dataset.imputer,  # ä½¿ç”¨è®­ç»ƒé›†çš„imputer
        scaler=train_dataset.scaler,  # ä½¿ç”¨è®­ç»ƒé›†çš„scaler
        is_train=False  # æ ‡è®°éªŒè¯é›†
    )

    if train_subset_ratio < 1.0:
        subset_size = int(train_subset_ratio * len(train_dataset))
        train_dataset = torch.utils.data.Subset(train_dataset, range(subset_size))

    batch_size = 128
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # è®¡ç®— floor_weights æ—¶ï¼Œæ­£ç¡®å¤„ç† Subset æƒ…å†µ
    if isinstance(train_loader.dataset, Subset):
        # å¦‚æœæ˜¯ Subsetï¼Œé€šè¿‡ .dataset è®¿é—®åŸå§‹æ•°æ®é›†çš„ labels
        floor_counts = np.bincount(train_loader.dataset.dataset.labels)
    else:
        # å¦åˆ™ç›´æ¥è®¿é—® labels
        floor_counts = np.bincount(train_loader.dataset.labels)

    return train_loader, val_loader, num_buildings, num_floors, floor_counts, coord_mean, coord_std


# ä¸»å‡½æ•°
def main():
    # åˆå§‹åŒ–é…ç½®
    model_config = {
        'input_dim': 520,
        'spatial_feature_dim': 256,  # å¯¹åº”cnn_channels
        'temporal_hidden_dim': 512,  # å¯¹åº”gru_hidden_size
        'temporal_feature_dim': 256,  # GRUè¾“å‡ºç»´åº¦ä¿æŒä¸ç©ºé—´ç‰¹å¾ç›¸åŒ
        'eca_channels': 512,
        'num_classes': None,
        'fc1_dropout': 0.5,  # æ–°å¢å‚æ•°
        'dae_noise_std': 0.02  # æ–°å¢å‚æ•°
    }

    # è®¾ç½®è·¯å¾„
    # åœ¨ä¸»å‡½æ•°ä¸­ä¿®æ”¹è¿™ä¸¤è¡Œ
    TRAIN_PATH = '/kaggle/input/ujiindoorloc/TrainingData.csv'
    VAL_PATH = '/kaggle/input/ujiindoorloc/ValidationData.csv'
    # åŠ è½½å¹¶åˆ†å±‚åˆ’åˆ†æ•°æ®
    train_loader, val_loader, num_buildings, num_floors, floor_counts, coord_mean, coord_std = load_and_preprocess_data(
        train_data_path=TRAIN_PATH,
        val_data_path=VAL_PATH,
        train_subset_ratio=1.0,
    )
    train_dataset_size = len(train_loader.dataset)
    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {train_dataset_size}")

    # æ›´æ–°æ¨¡å‹é…ç½®
    model_config['num_classes'] = num_buildings + num_floors
    model_config['num_buildings'] = num_buildings
    model_config['num_floors'] = num_floors
    print(f"æ¨¡å‹é…ç½®: å»ºç­‘æ•°é‡={num_buildings}, æ¥¼å±‚æ•°é‡={num_floors}")

    # åˆå§‹åŒ–æ¨¡å‹
    model = WiFiLocalizationModel(model_config)

    # æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)
    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-2)
    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    #     optimizer, mode='min', factor=0.7, patience=3
    # )

    num_epochs = 60

    scheduler = StepLR(optimizer, step_size=15, gamma=0.5)

    print(f"Scheduler is of type: {type(scheduler)}")

    # è®¡ç®—æ¥¼å±‚æƒé‡
    floor_weights = 1.0 / (floor_counts + 1e-7)
    floor_weights = torch.tensor(floor_weights, dtype=torch.float32).to(device)

    # ä½¿ç”¨ FocalLoss æˆ– CrossEntropyLoss
    # floor_loss_fn = FocalLoss(alpha=floor_weights, gamma=2)
    floor_loss_fn = nn.CrossEntropyLoss(weight=floor_weights, label_smoothing=0.05)

    # å¯åŠ¨è®­ç»ƒ
    train_losses, val_losses = train_model(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        floor_loss_fn=floor_loss_fn,
        criterion=criterion,
        scheduler=scheduler,
        optimizer=optimizer,
        num_epochs=60,
        patience=20,
        coord_mean=coord_mean,
        coord_std=coord_std,
        flood_level=0.3,  # è®¾ç½® Flooding é˜ˆå€¼ï¼ˆå¯è°ƒæ•´ï¼‰
        device=device  # æ·»åŠ è¿™è¡Œ
    )

    logger.info("âœ… Training completed!")


if __name__ == '__main__':
    main()
















